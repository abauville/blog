{
  
    
        "post0": {
            "title": "Superpixels",
            "content": "A typical image may contain millions of pixels, which makes operation on images and computer vision in general pretty expensive computationally. However, most of the image is actually composed of relatively large regions of similar color. Thus, if we can identify these regions we can efficiently reduce the size of the image while keeping most of the relevant information, i.e. color and edges. Enter superpixels. &quot;Superpixels group pixels similar in color and other low-level properties&quot; (Stutz et al.). They can be used to improve the computational efficiency for problems such as image segmentation, tracking, or 3-D reconstruction. . According to Stutz et al., superpixels must have the following properties: &quot; . Partition. Superpixels should define a partition of the image, i.e. superpixels should be disjoint and assign a label to every pixel. | Connectivity. Superpixels are expected to represent connected sets of pixels. | Boundary Adherence. Superpixels should preserve image boundaries. Here, the appropriate definition of image boundaries may depend on the application. | Compactness, Regularity and Smoothness. In the absence of image boundaries, superpixels should be compact, placed regularly and exhibit smooth boundaries. | Efficiency. Superpixels should be generated efficiently. | Controllable Number of Superpixels. The number of generated superpixels should be controllable.&quot; | . In recent years, SLIC has emerged as a popular algorithm for image segmentation into superpixel. Fundamentally, SLIC works by performing K-means clustering on a 5D feature space composed of color and space (xy). The CIELAB color space is prefered over RGB because it is more visually homogeneous. . In this blogpost I will implement an algorithm for superpixel segmentation that is fundamentally similar to SLIC, i.e. clustering over color and spatial feature space. There a two important parameters in the algorithm: the relative weight given to color and spatial features (called &quot;compactness&quot; in SLIC), and the number of superpixels. SLIC uses an initial cluster centroid positioning and partial neighborhood calculation to speed up the computation. For the purpose of clarity and to allow for some more exploration, I ignore these aspects. Because of these different choices, I also employ a different method to ensure connectivy. My implementation is based on skimage, sklearn and numpy, with matplotlib for visualization. . Setup . We start by importing the necessary libraries and some helper functions for plotting. . # imports import skimage as ski import matplotlib.pyplot as plt import numpy as np from im_func import show_image, show_multi_image, timer import seaborn as sns from skimage import transform from skimage import io from skimage import segmentation from sklearn.cluster import MiniBatchKMeans . . Then, we import an image and we compute a SLIC segmentation using the skimage implementation for reference. Here, we used a compactness of 20 and 100 superpixels. We reconstruct an image for the segmentation using skimage&#39;s label2rgb function. . title = &#39;coffee&#39; image = getattr(ski.data, title)() # Resize the image image = ski.transform.rescale(image,1/1,multichannel=True) segments = segmentation.slic(image, compactness=20, n_segments=100, start_label=1) image_SLIC = ski.color.label2rgb(segments, image, kind=&#39;avg&#39;, bg_label=0) _ = show_multi_image(((image, title), (image_SLIC, &#39;Reference: SLIC superpixel&#39;)), figsize=[20,20]) . Our method . We create a function segment_image that performs three steps. . 1. Prepare data . We modify the original image in two ways: we apply a gaussian filter to reduce the noise and smooth high frequency features, and we convert the image from RGB to CIELAB color space, and scale it in the range 0-1. For space, we create two matrices to store the x and y position of every pixel. The x coordinate goes 0 to W, and the y coordinate from 0 to W*width/height. Then, we merge color and space into a n*5 matrix, where n is the number of pixels. . W is a parameter that weights the importance of space compared to color, and thus serves the same purpose as compactness in SLIC. If W=1 space and color have equal importance; if W&gt;&gt;1, the clustering is effectively only affected by space; and if W~0 only color matters. . 2. Clustering . Finally, we apply the K-means clustering algorithm. Here, we use the MiniBatchKMeans function of sklearn to reduce computation time. We store the labels and cluster_centers for later use. . 3. Enforce connectivity . Following the definition given in the introduction, superpixels should represent connected sets of pixels. But our initial segmentation may not respect this constraint. If W&gt;&gt;1, then the the clustering is based only on spatial features, and connectivity is expected. But in the extreme case where W=0, pixels are grouped only by color, and therefore say, two black pixels in different corners of the image would be grouped together. To ensure the connectivity of superpixels for any values of W we do the following. . To verify connectivity we apply a flooding algorithm starting from one pixel in each cluster to flag pixels (like the paint bucket tool in drawing softwares). Once we have looped through unflagged pixels correspond to pixels belonging a part of one disconnected cluster. We loop apply flooding to remaining pixels, each time assigning a new cluster number until there are no unflagged pixel remaining. . Sometimes connectivity is not desired or required (e.g. for a filtering effect). Furthermore, when W&lt;&lt;1, the clustering may result in clusters with small disconnected regions. In that case enforce connectivity is expensive. Therefore connecitivity enforcement can be switched off. . 4. Function . The function segment_image takes five arguments: . an image | K: number of clusters | W: relative importance of space compared to color | sigma: intensity of gaussian filtering | enforce_connectivity: (boolean) specifies whether or not to enforce connectivity | . def segment_image(image, K=100, W=3.0, sigma=2.0, enforce_connectivity=True, output_type=&#39;image&#39;): &quot;&quot;&quot;Segments an image into superpixels by using K-Means clustering and connectivity enforcement Parameters - image: array Input image in RGB format. K: int, default=100 Number of superpixels (i.e. number of clusters). W: float, default=3.0 Relative importance of space of color during clustering. sigma: float, default=2.0 Standard deviation for Gaussian kernel. enforce_connectivity: bool, default=True Whether to enforce the connectivity of clusters. output_type: str, default=&#39;image&#39; whether to output &#39;image&#39; or &#39;labels&#39;. In case of &#39;image&#39;, an image is computed from the labels using the average color in the cluster. Returns - if output_type==&#39;image&#39;: segmented_image: array an RGB image computed from the labels if output_type==&#39;labels&#39;: labels: array an array containing the label (i.e. cluster) of each pixel &quot;&quot;&quot; # Prepare data # ====================================== # Apply gaussian filter image_filtered = ski.filters.gaussian(image, sigma=sigma, multichannel=True) # Convert the image to CIELAB image_filtered = ski.color.rgb2lab(image_filtered)/100.0 # Define space X,Y = np.meshgrid(np.linspace(0,1.0*W,image.shape[0]),np.linspace(0,1.0*W*image.shape[1]/image.shape[0],image.shape[1])) X = X.T; Y = Y.T # Merge space and color matrices data = np.concatenate([(image_filtered), np.stack([X,Y],axis=2)],axis=2) data = data.reshape(image.shape[0]*image.shape[1],-1) # Cluster # ====================================== clustering = MiniBatchKMeans(n_clusters=K, random_state=12).fit(data) labels = clustering.labels_.reshape(image.shape[:-1]) cluster_centers = clustering.cluster_centers_ cluster_centers[:,-2] *= image.shape[0]/W cluster_centers[:,-1] *= np.max(Y)/W # Enforce connectivity # ====================================== if enforce_connectivity: image_flooded = labels.copy() ic = 0 for i,j in cluster_centers[:,-2:].astype(int): if image_flooded[i,j] == ic: seed = (i,j) else: # if the cluster is disconnected or has a twisty shape, the cluster_center&#39;s pixel may be outside the actual cluster # then find one point in the cluster seed = tuple(np.argwhere(image_flooded==ic)[0]) ski.morphology.flood_fill(image_flooded, seed, -1, in_place=True) ic+=1 nseed = np.max(labels) disconnected = np.argwhere(image_flooded&gt;=0) while len(disconnected&gt;0): seed = tuple(disconnected[0]) nseed += 1 ski.morphology.flood_fill(labels, seed, nseed, in_place=True) ski.morphology.flood_fill(image_flooded, seed, -1, in_place=True) disconnected = np.argwhere(image_flooded&gt;=0) # Return # ====================================== if output_type.lower()==&#39;labels&#39;: return labels elif output_type.lower()==&#39;image&#39;: return ski.color.label2rgb(labels, image, kind=&#39;avg&#39;, bg_label=-1) else: raise ValueError(f&quot;Unkown output_type {output_type}. Accepted values are &#39;image&#39; or &#39;labels&#39;.&quot;) . Results . The figure below illustrates the influence of the parameters K (number of superpixels) and W (weight of space over color). When W=0, the partition is based only on color and the image always remain recognizable, even when the number K is small (e.g. 10). However, these clusters may be disconnected, and once if enforce connectivity the actual number of cluster may increase sharply. On the other hand, when W=100, the segmentation is based effectively on space only. A hexagonal pattern which corresponds to the voronoi diagram appears. Since this pattern doesn&#39;t conserve edges, a large number of superpixel, K, is necessary to recognize the picture. Overall, for the purpose of superpixel segmentation W=3 and K=100-500 yields good results. . image_list = [] W_list = [0.01, 0.3, 1.0, 3.0, 100] K_list = [10, 100, 500] for K in K_list: for W in W_list: # Add a print statement that overwritten at each step image_list.append( (segment_image(image,W=W, K=K, enforce_connectivity=False), f&#39;W={W:.1f}, K={K:.1f}&#39;) ) _ = show_multi_image(tuple(image_list), row_col=(len(K_list),len(W_list)), figsize=[13,6], tight_layout=True) . . Visualizations . Contours . Now that we have successfully segmented our original image with superpixels we can add a couple more improvements to the visualization. First, we extract the superpixel contours, thicken them and impose those contours to the segmented image for a tainted glass effect. . # Get edges and superpose them to the original picture labels = segment_image(image,W=4.0, K=150, sigma=2.5, enforce_connectivity=True, output_type=&#39;labels&#39;) image_seg = ski.color.label2rgb(labels, image, kind=&#39;avg&#39;, bg_label=-1) im_bound = ski.segmentation.find_boundaries(labels) im_out = ski.morphology.dilation(im_bound,selem=ski.morphology.square(2)) im_bound_thick = ski.segmentation.find_boundaries(labels) # im_out = image_sobel image_seg_contour = image_seg.copy() image_contour = image.copy() for i in range(3): image_seg_contour[:,:,i] *= 1.0-im_out image_contour[:,:,i] *= 1.0-im_out _ = show_multi_image(((im_bound,&#39;contours&#39;), (im_out,&#39;thick contours&#39;), (image_seg_contour,&#39;seg+contour&#39;), (image_contour,&#39;original+contour&#39;) ),figsize=[14,10],row_col=(2,2),tight_layout=True) . . Blending the original, segmented and contoured images . We can also blend the original image and the segmented one to obtain a subtle painting effect. . _ = show_multi_image([(fac*image + (1.-fac)*image_seg, f&#39;fac: {fac:.2f}&#39;) for fac in [1., .66, .33, .0]], figsize=[14,10], tight_layout=True) . . Finally, we gradually blend (i.e. crossfade) the original, segmented and countoured image together. . # Generate a gradually blended image ny = image.shape[1] x = np.zeros((1,image.shape[1])) lim = 2*ny/3 pad = 40 def crossfade_images(image1, image2, lim=ny/2, pad=5): # image1 and image2 should be the same size for i in range(x.shape[1]): if i &lt; lim-pad: x[0,i] = 1. elif i &gt; lim+pad: x[0,i] = 0. else: x[0,i] = .5-(i-lim)/(2*pad) X = np.ones((image.shape[0],1))@x return (image1.T*X.T).T.reshape(image1.shape) + (image2.T*(1.-X.T)).T.reshape(image2.shape) new_image = crossfade_images(image, image_seg,lim=ny*.45, pad=100) new_image = crossfade_images(new_image, image_seg_contour,lim=ny*.85, pad=100) _ = show_image(new_image,figsize=[10,10]) . . Conclusion . I created a superpixel algorithm that includes most ingredients according to the definition of Stutz et al. The algorithm is based on K-means clustering with an additional step to enforce connectivity. The algorithm partitions the image into small connected regions of similar color. The algorithm offers the flexibility to choose the number of superpixel (parameter K) and how to weigh space vs color (parameter W). . Enforcing connectivity is the most expensive step. For the purpose of superpixel segmentation the ideal W is 1-10. In this range the algorithm is quite efficient. Enforcing connectivity can, however, be expensive in the case where W~0 because the initial partition is only based on color. But, that case is not ideal for superpixel. . Compared to the popular SLIC algorithm, our algorithm results in a segmentation that is more hexagonal, whereas SLIC creates rather square regions. In addition, our algorithm can create relatively small regions. Both effects are due to a different choice of initial cluster positions. . I also showed how to contour and blend images which can be useful for specific technical or artistic purposes. .",
            "url": "https://abauville.github.io/data_science_blog/2021/05/10/_05_11_superpixel.html",
            "relUrl": "/2021/05/10/_05_11_superpixel.html",
            "date": " • May 10, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "WaiDatathon 2021 - "Combat domestic violence with data and AI"",
            "content": "WaiDatathon 2021: &quot;Combat domestic violence with data and AI&quot; . . Content . Problem description | Setup | Acceptability vs experience of domestic violence | Analysis of the DHS women questionnaireAnalysis of the DHS women questionnaire Feature selection | Data cleaning | Exploratory data analysis | | Modeling Data cleaning | Feature predictivity | Model training | Final result: personalized questionnaire | Discussion | | Conclusion | . 1. Problem description . The WaiDatathon 2021 was organized by Women in AI on the theme &quot;Combat Domestic Violence with Data &amp; AI&quot;. This notebook reproduces our main analysis for which we earned the first place at the competition. . Many professionals including social workers, medical professionals, academics, politicians or police agents are working daily to help women in abusive relationships, raise awareness in the general public and overall fight this phenomenon. Despite their efforts domestic violence is still a critical but hidden problem all around the world. When approaching this challenge it was clear for us that no amount of machine learning would solve the problem. Domestic violence is a sensitive and emotional topic for the victims. One of machine learning greatest strength is its ability to automate complex tasks, but domestic violence is a deeply human problem, and we believe that humans are the most important part of the support mechanism. . Three human parties are involved in domestic violence: the victim, the abuser and the supporters. We approached the challenge in two parts. Firstly, we addressed the victim&#39;s point of view. In particular, we tried to understand the relationships between the attitudes toward domestic and its occurence, and how these are affected by demographic characteristics. Secondly, we tried to provide an additional tools to supporters in order to detect women in danger. For this purpose we proposed a machine learning model that creates a questionnaire to detect early signs of domestic violence. Because the model can be deployed on paper or by dialogue, it is especially suited for developing countries. . You can watch our 5-minute competition talk here. The original notebook, data and presentation slides are available on the project&#39;s github repository. . . . 1. Dataset description . Our analysis is based on the amazing data from The Demographic and Health Surveys (DHS) Program. This DHS program&#39;s goal is to collect, analyze and disseminate accurate and representative data on population, health, HIV and nutrition. It has run more than 400 surveys in 90 countries. . The dataset provided competition contains the results to the acceptability question (see below) aggregated per demographics (e.g. age, education, location). In other terms, this dataset contains information such as &quot;70% of respondents with a secondary level of education answered &#39;yes&#39; to a given question&quot;. However, since it does not contain the demographic information and answers of individual respondents it was not possible to cross mutliple information (e.g. age and education) or to build a predictive model. . To overcome this difficulty we obtained the complete DHS survey&#39;s women&#39;s questionnaire for Sub-Saharan countries. This dataset contains the response of individual respondents (samples) to thousands of questions (features). For a given country and a given survey phase the dataset would contain in the order of 10,000 samples and 4200 features. However, due to time constraints and the necessity to clean the data we did not use all the features but selected a subset of 38 questions. . For the competition we used data of the DHS survey for Benin and Congo, but to comply with copyright requirements of the DHS program only the example data of the DHS survey or generated by STATcompiler are contained in this github repository. Access to more data is free upon request on the DHS website. This notebook can be used to treat any survey data from the DHS women&#39;s questionnaire. However, since the survey questions are revised from one phase to another, some adjustements might be required in the data cleaning process when using earlier phases. . Some of the most important features for our analysis were in the form of multiple short questions on a given theme. We treated these questions either as: . individual features | a sum of positive answer (for a given theme) | a boolean value (True if any question on a theme was answered true, False otherwise) | . Below, we list these questions with their possible answers. . Important questions . Acceptability of violence: . Feature names: v744a - v744f Possible answers: . 0 No | 1 Yes | 8 Don&#39;t know | (m) 9 Missing | (na) Not applicable | . In your opinion, is a husband justified in hitting or beating his wife when: . she goes out without telling him? | she neglects the children? | she argues with him? | she refuses to have sex with him? | . marital control behaviors: . Feature name: d101a - d101e Possible answers: see previous . Does your husband: . become jealous or angry if you talks to other men? | frequently accuses you of being unfaithful? | not permit you to meet your female friends? | tries to limit your contact with your family? | insists on knowing where you are at all times? | not trust you with money? | . Physical violence: . Feature names: d105a - d105k Possible answers: . 0 Never | 1 Often | 2 Sometimes | 3 Yes, but not in the last 12 months | 4 Yes, but frequency in last 12 months missing | (m) 9 Missing | (na) Not applicable | . Have you even been: . pushed, shook or had something thrown by husband/partner? | slapped by husband/partner? | punched with fist or hit by something harmful by husband/partner? | kicked or dragged by husband/partner? | strangled or burnt by husband/partner? | threatened with knife/gun or other weapon by husband/partner? | physically forced into unwanted sex by husband/partner? | forced into other unwanted sexual acts by husband/partner? | had arm twisted or hair pulled by husband/partner? | physically forced to perform sexual acts respondent didn&#39;t want to? | . Emotional violence: . Feature names: d103a - d103c Possible answers: see previous . Have you ever benn: . humiliated by husband/partner? | threatened with harm by husband/partner? | insulted or made to feel bad by husband/partner? | . . 2. Setup . First we import libraries, customize figure output and load the data. . # Import libraries import matplotlib.pyplot as plt import matplotlib as mpl import pandas as pd import numpy as np import seaborn as sns import plotly.express as px import plotly.graph_objects as go from IPython.display import HTML # Customize figure output plt.style.use(&#39;seaborn&#39;) mpl.rc(&#39;font&#39;, size=18) mpl.rc(&#39;axes&#39;, labelsize=&#39;large&#39;) mpl.rc(&#39;xtick&#39;, labelsize=&#39;large&#39;) mpl.rc(&#39;ytick&#39;, labelsize=&#39;large&#39;) plt.rcParams[&#39;figure.figsize&#39;] = [20, 10] # For larger plots . . . 3. Acceptability vs experience of domestic violence . df = pd.read_csv(&#39;./Data/DHS_summary_world.csv&#39;, skiprows=1, skipfooter=11,engine=&#39;python&#39;) df = df.merge(pd.read_csv(&#39;./Data/iso_alpha_list.csv&#39;), left_on=&#39;Country&#39;, right_on=&#39;country&#39;,how=&#39;left&#39;) # Sample only the most recent survey for each country country_list = df[&#39;Country&#39;].unique().tolist() temp = [df[df[&#39;Country&#39;]==country].reset_index().iloc[0] for country in country_list] df = pd.DataFrame(temp).reset_index().drop(columns=[&#39;level_0&#39;,&#39;index&#39;]) . . # Distributions x = &quot;Wife beating justified for at least one specific reason&quot; y = &quot;Physical violence committed by husband/partner in last 12 months&quot; y_list = [x + &quot; [Men]&quot;, x + &quot; [Women]&quot;] temp = df[y_list].copy().rename(dict(zip(y_list,[&quot;Men&quot;, &quot;Women&quot;])),axis=1) fig = px.violin(temp,box=True,title=x) fig.update_layout(title=dict(x=0.5,font=dict(family=&#39;Futura&#39;))) HTML(fig.to_html()) . . . . # Scatter plot of xperience vs acceptability of violence from sklearn.linear_model import LinearRegression # Data selection x = &quot;Wife beating justified for at least one specific reason&quot; y = &quot;Physical violence committed by husband/partner in last 12 months&quot; colors = [&#39;red&#39;,&#39;blue&#39;] # Figure layout fig = go.Figure(layout=dict(height=600, xaxis=dict( title=x), yaxis=dict( title=y), legend=dict( title=&#39;country&#39;), title=&#39;Experience vs acceptability of violence&#39;)) xlim = np.array([0,85]) ylim = np.array([0,50]) trace_flag = [] # flagging info for visualization: 0 for women, 1 for men, 2 for both # Compute and plot regression lines model = LinearRegression() for i, gender in enumerate([&quot; [Women]&quot;, &quot; [Men]&quot;]): df_fit = df[[x + gender, y]].dropna() X = df_fit[x + gender].values.reshape(-1, 1) model.fit(X, df_fit[y]) x_range = xlim y_range = model.predict(x_range.reshape(-1, 1)) fig.add_traces(go.Scatter(x=x_range, y=y_range, name=&#39;Regression&#39; + gender, line=dict(color=colors[i],width=1), marker=dict(opacity=0)), ) trace_flag.append(i) # Plot points for Women, Men and for i in range(df.shape[0]): # loop over countries fig.add_trace(go.Scatter(x=df[[x + &quot; [Women]&quot;]].iloc[i], y=[df[y].iloc[i]], marker=dict(color=[&#39;Red&#39;]), line=dict(color=&#39;rgb(210,210,210)&#39;,width=1), name=df[&#39;Country&#39;].iloc[i], )) trace_flag.append(0) fig.add_trace(go.Scatter(x=df[[x + &quot; [Men]&quot;]].iloc[i], y=[df[y].iloc[i]], marker=dict(color=&#39;Blue&#39;), line=dict(color=&#39;rgb(210,210,210)&#39;,width=1), name=df[&#39;Country&#39;].iloc[i], )) trace_flag.append(1) # Plot a line that connects men and women for a given country for i in range(df.shape[0]): fig.add_trace(go.Scatter(x=df[[x + &quot; [Men]&quot;, x + &quot; [Women]&quot;]].iloc[i], y=[df[y].iloc[i],df[y].iloc[i]], # color_discrete_sequence=[&#39;red&#39;], line=dict(color=&#39;rgb(210,210,210)&#39;,width=1), marker=dict(size=0,color=&#39;black&#39;,opacity=0), name=df[&#39;Country&#39;].iloc[i], )) trace_flag.append(2) trace_flag = np.array(trace_flag) # Update title, and axes range fig.update_layout(title=dict(x=0.5,font=dict(family=&#39;Futura&#39;))) fig.update_xaxes(range=xlim) fig.update_yaxes(range=ylim) # GUI fig.update_layout( updatemenus=[ dict( type=&quot;buttons&quot;, direction=&quot;right&quot;, active=0, xanchor=&#39;left&#39;, x=0.01, yanchor=&#39;top&#39;, y=0.98, buttons=list([ dict(label=&quot;Women and Men&quot;, method=&quot;restyle&quot;, args = [{&#39;visible&#39;: np.ones(len(trace_flag))}], ), dict(label=&quot;Women only&quot;, method=&quot;restyle&quot;, args = [{&#39;visible&#39;: trace_flag==0}] ), dict(label=&quot;Men only&quot;, method=&quot;restyle&quot;, args=[{&#39;visible&#39;: trace_flag==1}]), ]) ) ] ) HTML(fig.to_html()) . . . . There seems to be a certain correlation between acceptability and experience of violence although the data are quite scattered. The regression line tells us that on average, for every 10% acceptability, domestic violence increases by ~2% (women acceptability) and 4% (men acceptability). In most countries the acceptability score is much higher than the experience score which indicates either that even woman who don&#39;t experience domestic violence find it acceptable or that domestic violence is largely unreported. . # create figure acc = &quot;Wife beating justified for at least one specific reason&quot; + &quot; [Women]&quot; exp = &quot;Physical violence committed by husband/partner in last 12 months&quot; fig = go.Figure(layout=dict(width=900,height=550)) hover_text = &#39;country: &#39; + df[&#39;country&#39;] + &quot;&lt;br&gt;&quot; + &#39;experience: &#39; + df[exp].astype(str) + &#39; %&lt;br&gt;&#39; + &#39;acceptability: &#39; + df[acc].astype(str) + &#39; %&lt;br&gt;&#39; # Add surface trace fig.add_trace(go.Choropleth(z=(df[acc]-df[exp])/df[acc].values.tolist(), locations=df[&#39;iso_code&#39;].values.tolist(), text=hover_text, hoverinfosrc=&#39;text&#39;, visible=False, zmin=-1.0, zmax=1.0, colorscale=&#39;PiYG_r&#39;, colorbar=dict(title=dict(text=&#39;(acc-exp)/acc []&#39;,side=&#39;right&#39;)) )) fig.add_trace(go.Choropleth(z=df[exp].values.tolist(), locations=df[&#39;iso_code&#39;].values.tolist(), text=hover_text, hoverinfosrc=&#39;text&#39;, colorscale=&quot;Greens&quot;, visible=False, colorbar=dict(title=dict(text=&#39;experience [%]&#39;,side=&#39;right&#39;)) )) fig.add_trace(go.Choropleth(z=df[acc].values.tolist(), locations=df[&#39;iso_code&#39;].values.tolist(), text=hover_text, hoverinfosrc=&#39;text&#39;, colorscale=&quot;Reds&quot;, colorbar=dict(title=dict(text=&#39;acceptability [%]&#39;,side=&#39;right&#39;)) )) fig.update_layout(title=dict(x=0.5, text=&#39;World distribution of acceptability and experience of domestic violence&#39;, font=dict(family=&#39;Futura&#39;))) fig.update_layout( updatemenus=[ dict( type=&quot;buttons&quot;, direction=&quot;right&quot;, active=0, xanchor=&#39;center&#39;, yanchor=&#39;bottom&#39;, x=0.5, y=1.02, buttons=list([ dict(label=&quot;Acceptability&quot;, method=&quot;restyle&quot;, args = [{&#39;visible&#39;: [False, False, True]}] ), dict(label=&quot;Experience&quot;, method=&quot;restyle&quot;, args=[{&#39;visible&#39;: [False, True, False]}]), dict(label=&quot;(Acceptatbility-Experience)/Acceptability&quot;, method=&quot;restyle&quot;, args = [{&#39;visible&#39;: [True, False, False]}]), ]), showactive=True,) ]) HTML(fig.to_html()) . . . . The above figure shows the distribution of acceptability and experience of violence among women. Here, violence is considered as &quot;acceptable&quot; for the respondent if she answered any of the acceptability question positively. Here, the experience of violence corresponds to any positive answer (answer other than &quot;never&quot;) to any of the physical violence question. The dataset was generated using STATcompiler. . Acceptability is calculated as the percentage of women who answered &quot;True&quot; to at least one of the acceptability question. While experience counts the percentage of women who answer &quot;yes, in the last twelve&quot; to at least one of the physical violence question. The (normalized) difference map is computed as $(acceptability-experience)/acceptability$. . Both acceptability and experience are highest in Afghanistan. Acceptability is highest in subsaharan african countries, middle east and south/southeast Asia, and lowest in Europe and Latin America. Experience is above 10% in most countries and highest in Papua New Guinea and Afghanistan. The difference map shows, in green, countries where acceptability is lower experience than experience. This situation may be seen as a good thing if we consider that public awareness may drive a change in society as suggested by the fact that these countries have relatively lower experience percentage points. In countries colored purple experience is higher than acceptability. These countries tend to have relatively high experience scores. Angola has a score close to 0, due to a relatively low acceptability but high experience. Could this low acceptability score signal that a change is about to come in Angola? . The numbers shown here, and especially the experience score must be taken as lower bounds since domestic violence is most likely under-reported. . . 4. Analysis of the DHS women questionnaire . . 1. Feature selection . First, we load the DHS women questionnaire model dataset. . # Load data df_IR = pd.read_stata(&quot;./Data/ZZIR62FL.DTA&quot;, convert_categoricals=False) print(f&quot;Number of samples: {df_IR.shape[0]}&quot;) print(f&quot;Number of features: {df_IR.shape[1]}&quot;) . . Number of samples: 8348 Number of features: 4275 . Then, we manually select a subset of features. We store the code of each feature in variable with a more explicit name. . # Subset of features # background edu = &#39;v106&#39; # education violence_justified = &#39;v744&#39; # a-e age = &#39;v012&#39; age_group = &#39;v013&#39; litteracy = &#39;v155&#39; media_paper = &#39;v157&#39; media_radio = &#39;v158&#39; media_tv = &#39;v159&#39; sample_weight = &#39;v005&#39; # must be divided by 1e6 ever_married = &#39;v020&#39; # residence = &#39;v025&#39; time2water = &#39;v115&#39; has_elec = &#39;v119&#39; has_radio = &#39;v120&#39; has_tv = &#39;v121&#39; has_fridge=&#39;v122&#39; has_bicycle = &#39;v123&#39; has_moto = &#39;v124&#39; has_car = &#39;v125&#39; religion = &#39;v130&#39; ethnicity = &#39;v131&#39; place_of_residence = &#39;v134&#39; edu_attainment = &#39;v149&#39; relation2household_head=&#39;v150&#39; sex_household_head = &#39;v151&#39; age_household_head = &#39;v152&#39; has_phone_landline=&#39;v153&#39; has_phone_mobile=&#39;v169a&#39; use_internet = &#39;v171a&#39; use_internet_last_month = &#39;v171b&#39; wealth_index = &#39;v191&#39; total_child_born = &#39;v201&#39; num_sons_died = &#39;v206&#39; num_daughters_died = &#39;v207&#39; num_dead_child = &#39;num_dead_child&#39; num_living_child = &#39;v218&#39; husband_edu_level = &#39;v701&#39;# &#39;s904&#39; husband_occupation = &#39;s908a&#39; resp_occupation = &#39;s913a&#39; # Domestic violence selected_for_dom_violence_interview = &#39;v044&#39; is_currently_in_union= &#39;v502&#39; weight_dom_violence = &#39;d005&#39; control_issues = &#39;d101&#39; #a-j num_control_issues = &#39;d102&#39; emotional_violence = &quot;d103&quot; # a-f emotional_violence_any = &#39;emotional_violence_any&#39; #&#39;d104&#39; physical_violence = &#39;d105&#39; # a-n detailed acts of violence physical_violence_less_severe = &#39;d106&#39; physical_violence_severe = &#39;d107&#39; sexual_violence = &#39;d108&#39; violence = &#39;violence&#39; # any_violence = &#39;d105&#39; or &#39;d106&#39; or &#39;d107&#39; violence_to_husband =&#39;d112&#39; partner_drinks_alcohol=&#39;d113&#39; partner_drinks_alcohol_freq = &#39;d114&#39; sought_help = &#39;d119&#39; # a to xk; y=no one mother_beaten = &#39;d121&#39; edu_w = &#39;v106&#39; # education level women, value =0-3 edu_m = &#39;mv106&#39; # education level men, #Age (v012) is recorded in #completed years, and is typically reported in 5-year groups (v013). # age_group_w = &quot;v013&quot; # Info for men is in the Men&#39;s individual recode (MR) dataset list_col0 = [&#39;caseid&#39;, &#39;v000&#39;, sample_weight, edu, age, age_group, litteracy, media_paper, media_radio, media_tv, ever_married, has_elec, has_radio, has_tv, has_fridge, has_bicycle, has_car, has_moto, has_phone_landline, # has_phone_mobile, religion, ethnicity, place_of_residence, age_household_head, relation2household_head, wealth_index, total_child_born, num_living_child, husband_edu_level, # husband_occupation, resp_occupation, selected_for_dom_violence_interview, weight_dom_violence, is_currently_in_union, num_control_issues, #emotional_violence_any, physical_violence_less_severe, physical_violence_severe, sexual_violence, partner_drinks_alcohol, partner_drinks_alcohol_freq, #sought_help, mother_beaten ] print(f&quot;Number of feature selected: {len(list_col0)}&quot;) . . Number of feature selected: 38 . . 2. Data cleaning . First we clean the data for our &quot;important questions&quot; (see intro). We encode these questions using one-hot encoding (True or False). And create new features as the sum of answers on a given topic. We will treat missing values (code 9) as False. We will consider True answers &quot;Yes&quot;, &quot;Often&quot;, or &quot;Sometimes&quot;. All other answer are consider false. The details of the possible answers are given in the next cell. NA values will be dealt with a a few cells later. . # Prepare clean format for multiple questions # Violence_justified # ======= &#39;&#39;&#39; V744A Beating justified if wife goes out without tell 6103 1 N I 1 0 No No 0 No 1 Yes 8 Don&#39;t know (m) 9 Missing (na) Not applicable &#39;&#39;&#39; # I assume 0 if v744 in [0, 8, 9, na]; 1 otherwise # Control issues # ======= &#39;&#39;&#39; D101A Husband/partner jealous if respondent talks wit 8272 1 N I 1 0 No No 0 No 1 Yes 8 Don&#39;t know (m) 9 Missing (na) Not applicable &#39;&#39;&#39; # For cleaning: same as previous # Physical or sexual violence # ======= &#39;&#39;&#39; D105A Ever been pushed, shook or had something thrown 8291 1 N I 1 0 No No 0 Never 1 Often 2 Sometimes 3 Yes, but not in the last 12 months 4 Yes, but frequency in last 12 months missing (m) 9 Missing (na) Not applicable &#39;&#39;&#39; # Let&#39;s consider true if hit during the past 12 months only # So, we clean as 0 if d105a in [0, 3,4,9,na] # Emotional violence # ======= &#39;&#39;&#39; D103A Ever been humiliated by husband/partner 8284 1 N I 1 0 No No 0 Never 1 Often 2 Sometimes 3 Yes, but not in the last 12 months 4 Yes, but frequency in last 12 months missing (m) 9 Missing (na) Not applicable &#39;&#39;&#39; # Same as physicial violence for cleaning cleaning_dict = { violence_justified: {&#39;ind&#39;: &#39;abcde&#39;, &#39;values_0&#39;: [8,9], &#39;values_1&#39;: [1]}, control_issues: {&#39;ind&#39;: &#39;abcdefghij&#39;, &#39;values_0&#39;: [8,9], &#39;values_1&#39;: [1]}, physical_violence: {&#39;ind&#39;: &#39;abcdefhijk&#39;, &#39;values_0&#39;: [3,4,9], &#39;values_1&#39;: [1,2]}, # ind: g skipped intentionally (NA) emotional_violence: {&#39;ind&#39;: &#39;abc&#39;, &#39;values_0&#39;: [3,4,9], &#39;values_1&#39;: [1,2]} } . . # Add multiple questions to list_col list_col = list_col0.copy() for key in cleaning_dict.keys(): cleaning_dict[key][&#39;list_col&#39;] = [key + letter for letter in cleaning_dict[key][&#39;ind&#39;]] list_col += cleaning_dict[key][&#39;list_col&#39;] . . Next we create a new dataframe that contains data only for the women who answered the domestic violence questionnaire. This will deal with the NA values. Then, we create the new xxx_sum features . # Create a subset dataframe that contains only the chosen columns # and only for women who are married and took the domestic violence interview df = df_IR[list_col].copy() df = df[df[is_currently_in_union]==1] df = df[df[selected_for_dom_violence_interview]==1] print(f&quot;Number of samples: {df.shape[0]}&quot;) print(f&quot;Number of features: {df.shape[1]}&quot;) . . Number of samples: 2017 Number of features: 66 . for key in cleaning_dict.keys(): df[key + &#39;_sum&#39;] = 0 for letter in cleaning_dict[key][&#39;ind&#39;]: df[key + letter].fillna(0, inplace=True) # There shouldn&#39;t be missing na because of preselection of samples, but just in case for i in cleaning_dict[key][&#39;values_0&#39;]: df.loc[df[key + letter] == i,key + letter] = 0 for i in cleaning_dict[key][&#39;values_1&#39;]: df.loc[df[key + letter] == i,key + letter] = 1 df[key + &#39;_sum&#39;] += df[key + letter] # Check that assignment is correct assert df[key + letter].max() &lt;= 1 # print(key + letter + &quot;:&quot;, df[key + letter].max()) . . . 3. Exploratory data analysis . temp = df[[violence_justified + &#39;_sum&#39;, physical_violence + &#39;_sum&#39;]].copy() temp[&#39;value&#39;] = 1 temp.loc[temp[physical_violence + &#39;_sum&#39;]&gt;=1, physical_violence + &#39;_sum&#39;]=1 temp.loc[temp[violence_justified + &#39;_sum&#39;]&gt;=1, violence_justified + &#39;_sum&#39;]=1 temp_pivot = temp.pivot_table(columns=[physical_violence + &#39;_sum&#39;], index=[violence_justified + &#39;_sum&#39;], values=&#39;value&#39;,aggfunc=&#39;count&#39;) display(temp_pivot) plt.subplot(311) plt.title(&#39;Number of respondents for each class of score (only respondent not experience domestic violence)&#39;) sns.barplot(x=temp_pivot.index, y=temp_pivot.loc[:,0]) plt.subplot(312) plt.title(&#39;% of respondents experiencing domestic violence for each class&#39;) sns.barplot(x=temp_pivot.index, y=temp_pivot.loc[:,1]/temp_pivot.loc[:,0]) plt.subplot(313) plt.title(&#39;Number of respondents for each class of score (only respondent experiencing domestic violence)&#39;) sns.barplot(x=temp_pivot.index, y=temp_pivot.loc[:,1]) . . d105_sum 0.0 1.0 . v744_sum . 0.0 530 | 175 | . 1.0 902 | 410 | . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Number of respondents for each class of score (only respondent experiencing domestic violence)&#39;}, xlabel=&#39;v744_sum&#39;, ylabel=&#39;1.0&#39;&gt; . subplot(1) most respondents answered no to every question (ie v744_sum == 0) | subplot(2) Given the v744 score, the probability to experience violence is higher for higher scores (i.e., P(A|B), where A is score and B is violence) | subplot(3) since there are many more people with a score of 0, most people experiencing violence scored 0 (i.e. P(B|A)) | . The results from subplot 2 and 3, are typical examples of bayesian probability. . What is the most common form of physical+sexual domestic violence? . key = physical_violence physical_violence_questions_sum = df[[key + letter for letter in cleaning_dict[key][&#39;ind&#39;]]].sum() num_physical_violence_respondent = (df[physical_violence + &#39;_sum&#39;]&gt;0).sum() . . question_list = [ &quot;pushed, shook or had something thrown at&quot;, &quot;slapped&quot;, &quot;punched with fist or hit by something harmful&quot;, &quot;kicked or dragged&quot;, &quot;strangled or burnt&quot;, &quot;threatened with knife/gun or other weapon&quot;, &quot;physically forced into unwanted sex&quot;, &quot;forced into other unwanted sexual acts&quot;, &quot;had arm twisted or hair pulled&quot;, &quot;physically forced to perform sexual acts&quot;, ] physical_violence_questions_sum.rename(dict(zip(physical_violence_questions_sum.index, question_list)),inplace=True) physical_violence_questions_sum.sort_values(ascending=False,inplace=True) sns.barplot(x=physical_violence_questions_sum/num_physical_violence_respondent*100, y=physical_violence_questions_sum.index,orient=&#39;h&#39;) . . &lt;AxesSubplot:&gt; . What are forms of violence that occur together? . phys_less = df[[&#39;d105a&#39;, &#39;d105b&#39;, &#39;d105c&#39;, &#39;d105j&#39;]].copy() phys_more = df[[&#39;d105d&#39;, &#39;d105e&#39;, &#39;d105f&#39;]].copy() sexual = df[[&#39;d105h&#39;, &#39;d105i&#39;, &#39;d105k&#39;]].copy() emo = df[[&#39;d103a&#39;, &#39;d103b&#39;, &#39;d103c&#39;]].copy() names = [&quot;emo&quot;, &quot;phys_less&quot;, &quot;phys_more&quot;, &quot;sexual&quot;] temp_dict = {} for name, this_df in zip(names, [emo, phys_less, phys_more, sexual]): temp_dict[name] = (this_df.sum(axis=1)&gt;0).astype(float) # this_df temp = pd.DataFrame(temp_dict) co_occurence = (temp.T@temp)#.astype(float)#.values for i in range(co_occurence.shape[0]): co_occurence.iloc[i,:] /= co_occurence.iloc[i,i] temp.head() temp[&#39;any&#39;] = (temp.sum(axis=1)&gt;0).astype(float) proba = temp.sum()/temp.shape[0] proba # co_occurence.head() # co_occurence = np.concatenate([ , co_occurence],axis=0) fig, ax = plt.subplots(1,2,figsize=(20,6)) plt.sca(ax[0]) sns.barplot(x=proba.index, y=proba) _ = plt.title(&quot;Probability event individual events&quot;,fontdict={&#39;fontsize&#39;:16}) plt.sca(ax[1]) co_occurence.style.background_gradient(cmap=&#39;magma&#39;, low=0.0, high=0.,axis=1) sns.heatmap(co_occurence*100,annot=True) ax = plt.gca() # ax.xaxis.grid(True, which=&#39;major&#39;) ax.set_yticklabels(co_occurence.index,fontdict={ &#39;verticalalignment&#39;: &#39;center&#39;,} ) _ = plt.title(&quot;Probability event A (column) given (event) B (row), i.e. P(A|B)&quot;,fontdict={&#39;fontsize&#39;:16}) xx, yy = np.meshgrid(np.arange(15),np.arange(15)) _ = plt.plot(xx.T,yy.T,&#39;w&#39;,lw=15) . . The above graph summarizes the forms of violence experienced by women in the last 12 months. Those results are for the model dataset and for the women who answered to the domestic violence questionnaire. The left graph shows that out of the respondents 21% experienced emotional violence, ~27% &quot;less severe&quot; physical violence, ~12% severe physical violence, ~4% sexual violence, and ~30% experience at least one of these kind of violence. The right graph shows the probability that a woman who experiences a form of violence B (row) also experiences the form of violence A. For example, the first row shows that woman who experience emotional violence also expereince less severe physical violence at 71%, severe physical violence at 34% and sexual violence at 12%. Here, we see that emotional violence is rarely isolated: more than 2/3 of women experiencing emotional violence also experience some form of physical violence. Overall experiencing emotional violence raises the likelihood of other acts of violence roughly by a factor of 3. For example, 4% of women from the general population experience sexual, while 12% of those who experience emotional violence do. However, emotional violence is not always experienced by women in abusive relationship: only 64% of women experiencing severe physical violence also experience emotional violence. It is a surprisingly low number compare to the 89% of women in that situation who also experience less severe violence. . . 5. Modeling . In this section we will attempt to predict which women is experiencing physical or sexual domestic violence based on their other answers to the DHS women questionnaire. More precisely, we will attempt to predict for any given woman, her answer (&quot;yes&quot; or &quot;no&quot;) to the question &quot;Have you experienced any form of physical or sexual domestic violence in the last 12 months?&quot;. In the following sections We quantify the predictivity of features based on the mutual information score and we build use a decision tree algorithm to build a very short personalized questionnaire whose goal is to identify women at risk of domestic violence. . . 1. Data cleaning and helper functions . For the clarity of output figures we further subset the dataset (we removed the less informative features based on the mutual information score). We clean those features to present them in a format suitable for modeling. . # Select some features for mutual information analysis list_col_model = [ litteracy, age, mother_beaten, wealth_index, num_living_child, edu, husband_edu_level, partner_drinks_alcohol_freq, control_issues + &#39;_sum&#39;, violence_justified + &#39;_sum&#39;, emotional_violence + &#39;_sum&#39;, physical_violence + &#39;_sum&#39;, ] X = df[list_col_model].copy() explicit_feature_names = [ &#39;Literacy&#39;, &#39;Age&#39;, &#39;Did your mother ever experience domestic violence?&#39;, &#39;wealth index&#39;, &#39;number of children&#39;, &#39;Education level&#39;, &quot;Husband&#39;s education level&quot;, &#39;How often does your husband drink alcohol?&#39;, &#39;Is your husband jealous, or not trusting you with money?&#39;, &#39;Is a husband justified to beat his wife?&#39;, &#39;Have you ever been humiliated, insulted or threatened by your husband?&#39;, ] # replace not applicable by &quot;doesn&#39;t drink&quot; for alcohol related question for col in [partner_drinks_alcohol_freq, mother_beaten]: X[col].fillna(0, inplace=True) # feature engineering age_diff = &#39;age_diff&#39; age_ratio = &#39;age_ratio&#39; X.loc[:,&#39;v701&#39;].fillna(0,inplace=True) # only 2 missing values in Congo, 0 in Benin X.loc[X[litteracy]&gt;=3,litteracy] = 0 X.loc[X[litteracy]&lt;=1,litteracy] = 0 X.loc[X[litteracy]==2,litteracy] = 1 # cast the following columns as int8 to treat them as discrete features for col in [ partner_drinks_alcohol_freq, mother_beaten, husband_edu_level]: X.loc[:,col] = X.loc[:,col].astype(&#39;int8&#39;) # /!  contains &quot;8&quot; as Nan # cast the following columns a floats continuous features for col in [num_living_child, #num_dead_child, total_child_born, age, #age_household_head, age_diff, violence_justified + &#39;_sum&#39;, emotional_violence + &#39;_sum&#39;, physical_violence + &#39;_sum&#39;, control_issues + &#39;_sum&#39;, wealth_index]: X[col] = X[col].astype(float) discrete_features = X.dtypes == &#39;int8&#39; X.dropna(inplace=True) . . # Mutual information classification from sklearn.feature_selection import mutual_info_classif def make_mi_scores(X, y, discrete_features): mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features) mi_scores = pd.Series(mi_scores, name=&quot;MI Scores&quot;, index=X.columns) mi_scores = mi_scores.sort_values(ascending=False) return mi_scores def plot_mi_scores(scores): scores = scores.sort_values(ascending=True) width = np.arange(len(scores)) ticks = list(scores.index) plt.barh(width, scores) plt.yticks(width, ticks) plt.title(&quot;Mutual Information Scores&quot;, fontsize=25) . . # Let&#39;s try subsampling the majority class (no violence) to get better classification on the minority class (i.e. the class of interest) from sklearn.model_selection import train_test_split def subsample(X,y,imbalance_fac=1): y_select = df[physical_violence + &quot;_sum&quot;]&gt;0 y_negative = y[y_select==0].copy() y_positive = y[y_select==1].copy() X_negative = X.loc[y_select==0,:].copy() X_positive = X.loc[y_select==1,:].copy() _, X_negative_sub, _, y_negative_sub = train_test_split(X_negative,y_negative, test_size=imbalance_fac*len(y_positive))#, stratify=True ) return (pd.DataFrame(np.concatenate([X_negative_sub,X_positive]), columns=X.columns), pd.Series(np.concatenate([y_negative_sub,y_positive]), )) . . . 2. Feature predictivity . for itarget, target_feature in enumerate([physical_violence]): y = X[target_feature + &#39;_sum&#39;]&gt;0 plt.subplot(1,2,itarget+1) this_X = X.drop(columns=[target_feature + &quot;_sum&quot;] ) discrete_features = this_X.dtypes == &#39;int8&#39; mi_scores = pd.Series(np.zeros(this_X.columns.shape), index= this_X.columns) n = 20 for i in range(n): X_sub, y_sub = subsample(this_X,y) mi_scores += 1.0/n*make_mi_scores(X_sub, y_sub, discrete_features) mi_scores.rename(dict(zip(X.columns,explicit_feature_names)), inplace=True) plot_mi_scores(mi_scores) . . The above bar graph shows the mutual information of the features selected for modeling. Mutual information measures how much information about our target value is gained by knowing the information related to the given feature. Here our target value is any positive answers to the question set about domestic physical or sexual violence, where a positive answer correspond to answers &quot;Often&quot; or &quot;Sometimes&quot;. We summarize the target question as: &quot;Have you experienced any form of physical or sexual domestic violence in the last 12 months?&quot;. By far the most predictive feature is the sum of answers to the question about emotional violence, which we summarize as &quot;Have you ever been humiliated, insulted or threatened by your husband?&quot;. We explored in detail the relation between emotional and physical/sexual violence in the &quot;exploratory data analysis&quot; section. The second most predictive feature is the sum of positive answers to the question set about controlling behavior of the husband. Then, come several demographic information such as age, wealth index, number of children, education, litteracy. We see that the acceptability of violence (&quot;Is a husband justified to beat his wife?&quot;) has much less predictivity than emotional violence or husband&#39;s controlling issues. However, it is slightly more predictive than husband&#39;s drinking habits. . . 3. Model training . Finally, we use the sklearn library&#39;s binary classification tree to create a model that predicts whether a woman has been experiencing deomestic violence in the last twelve month based on the set of features that we selected. A binary classification tree iteratively divides the features space in halves. At each stage the division of the space is chosen so that each new subdomain (or leaf) becomes &quot;purer&quot;. A &quot;pure&quot; leaf would only contain women experiencing domestic or only women not experiencing violence. A leaf where half in which half of the women experience violence and the other not would be &quot;unpure&quot;. . In our case, the &quot;True&quot; class corresponds to women already domestic violence. That means that the model&#39;s result can be divided as follows: . True positive ($TP$): women already experiencing domestic violence and correctly classified by the model | True negative ($TN$): women not experiencing domestic violence and correctly classified | False positive ($FP$): women not experiencing domestic violence but classified as &quot;experiencing violence&quot; by the model | False negative ($FN$): women experiencing domestic violence but not detected by the model | . Here, false negative are women already in danger but not deteced. Thus, the first priority of the model would be to limit false negatives. False positive may correspond to women who, although they are not experiencing domestic violence, may be in a situation where other forms of abusive are taking place such as emotional violence or controlling behaviors. For practical purpose interviewees classified as True positive or False positive should both be offered additional help. . Choice of performance metric . We need a metric to evaluate the model&#39;s performance and optimize the hyperparameters. We need to evaluate possible metrics based on the specific goals of our model. Typical metrics are: . accuracy: $ frac{TP+TN}{TP+FP+FN+TN}$ | F1-score: $ frac{2*TP}{2*TP+FP+FN}$ | precision: $ frac{TP}{TP+FP}$ | recall: $ frac{TP}{TP+FN}$ | negative predictive value: $ frac{TN}{TN+FN}$ | . In classification task, the most often used metric are accuracy and F1-score. However, both metrics as well as precision would tend to limit $FP$ which is against our objective. Since our primary objective is to limit the $FN$ &quot;recall&quot; and &quot;negative predictive value&quot; are the most adequate metrics. We chose recall because it would maximize $TP$, which is more interesting than $TN$ in our case. . Choice of hyperparameters to optimize . We optimize the minimum of samples per leaf. This parameter also implicitly controls the depth of the tree. For our purpose, we do not need the most accurate model possible since we keep a human in the loop. In practice, the model would be used by an interviewer as a tool to direct the early stages of an interview and form his opinion on whether the woman interviewed should be proposed specific help. In this sense the model prediction would probably be used in a qualitative rather than quantitative way. . from sklearn.tree import DecisionTreeClassifier from sklearn. ensemble import GradientBoostingClassifier, RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn import tree from sklearn.metrics import confusion_matrix, classification_report from sklearn.model_selection import GridSearchCV from sklearn.metrics import f1_score, roc_auc_score y = X[physical_violence + &quot;_sum&quot;]&gt;0 this_X = X.drop(columns=[physical_violence + &quot;_sum&quot;]) this_X = this_X.rename(dict(zip(this_X.columns,explicit_feature_names)),axis=1) discrete_features = this_X.dtypes == &#39;int8&#39; X_model = pd.get_dummies(this_X, columns=this_X.columns[discrete_features]) imbalance_fac = 1 X_model, y = subsample(X_model,y, imbalance_fac=imbalance_fac) X_train, X_test, y_train, y_test = train_test_split(X_model.values,y.values, test_size=0.2) param_grid = dict(max_depth=[9], min_samples_leaf=[0.01, 0.02, 0.03, 0.05, 0.07, 0.1, 0.15, 0.2], ) clf = DecisionTreeClassifier(min_impurity_decrease=0.0001, class_weight={0:1, 1:imbalance_fac}, ) clf_cv = GridSearchCV(clf, param_grid, cv=3, scoring=&#39;recall&#39;) clf_cv.fit(X_train, y_train) display(clf_cv.best_params_) y_pred = clf_cv.best_estimator_.predict(X_test) print(confusion_matrix(y_test, y_pred)/y_test.shape[0]) classif_dict = classification_report(y_test,y_pred, output_dict=True) print(&quot;f1_score:&quot;, classif_dict[&#39;True&#39;][&#39;f1-score&#39;]) print(classification_report(y_test,y_pred)) . . {&#39;max_depth&#39;: 9, &#39;min_samples_leaf&#39;: 0.05} . [[0.37179487 0.11111111] [0.11538462 0.4017094 ]] f1_score: 0.7800829875518671 precision recall f1-score support False 0.76 0.77 0.77 113 True 0.78 0.78 0.78 121 accuracy 0.77 234 macro avg 0.77 0.77 0.77 234 weighted avg 0.77 0.77 0.77 234 . Here, the optimal parameter was minimum number of samples per leaf (min_samples_leaf) of 0.05. . The model achieved a recall of 63% for the True class and a F1-score of 70% fo both classes. Next, we visualize the model results to get a better sense of the quality of the classification. . . 4. Final result: personalized questionnaire to indentify women at risk . _ = tree.plot_tree(clf_cv.best_estimator_, feature_names=X_model.columns, filled=True, impurity=False, proportion=True, precision=2, rounded=True,fontsize=11) . . Because all our features correspond to questions asked during the DHS questionnaire, each branching of the tree corresponds to question, and each branch to an answer. Unlike other machine learning algorithms, a decision tree can work with partial data. Firstly, because the tree doesn&#39;t use every single feature of the dataset to build a prediction. Secondly, because you only need the answers relative to path you are taking down the tree. Therefore, the model can be used to interview women. The interviewer would first ask the question at the root of the tree, and then ask the next relevant question depending on the answer given. . For example, the first question would be to ask the questions related to emotional violence (see introduction), which can be summarized as &quot;have you ever been humiliated, insulted or threatened by your husband?&quot;. If the interviewee answers &quot;yes&quot;, then the model predict that there is 89% chance that she experiences domestic violence, so she should be proposed further help. If she answers &quot;no&quot;, the next question would be to ask if there is a history of violence in her family, etc... . . 5. Discussion . As we mentionned earlier, classically the value of a model is to provide an accurate prediction. However, in our case the value of the model resides in: . The graph shown above which is the main tool: it allows an interviewer to direct an interview in the most efficient way possible. | The prediction. At each node of the model, the proportion of negative and positive class can be viewed as the probability that the interviewed woman needs further help. These predictions are probably more useful in a qualitative or a rough quantitative way. For example the probability can be divided into three buckets: | $&lt;30$% positive (orange) this woman doesn&#39;t need help | $30-70$% (white): this woman may need help | $&gt;70$%: this woman needs help | . Here, we used arbitrary limits of 30% and 70%, but in practice, these limits would be place by the interviewer or relevant organism depending their on objectives, budget, availability of helpers etc... And of course this short questionnaire can be just a small part of a longer interview. . We chose a decision tree as a model because it is transparent (i.e. white-box model) and can be used by humans using the output flow chart. However, decision trees have the inconvenient of not being robust. That means that slight changes in the data can result in a significantly different tree. In our experience, the root of the tree is very robust and never changes. The first level is also relatively robust. Beyond this level, different branches may occur. This points out to the fact that within random variations of the dataset many &quot;good&quot; questionnaires are possible, in the same way that a human interviewer would not ask always the same questions. Thus, we emphasize again that the decision tree constitutes a good tool to guide the decision process of a human interviewer. . However, the questions we identified are related to emotional violence and control issues. These are sensitive topic, and these questions may be perceived as intrusive. In that case, the interviewee may become uncomfortable or lie. Therefore, for practical purposes it might be beneficial to train the model with less informative but less intrusive questions such as demographics information. Both questionnaire could even be used together. First, the less intrusive questionnaire would be used for a first screening. The interviewee scoring above a predefined probably could then be asked questions from the more informative but more intrusive questionnaire, possibly by another person or in a more comfortable context. . . 6. Conclusion . Domestic violence is still an unsolved problem in 2021. The data from the Demographics and Health Survey reveal that in developing countries, a signifificant proportion of women (5-50%) report having experienced domestic violence in the last twelve months. Furthermore, on average, 35% of women think that this violence is justified. . In this report, we presented an extended version of our contribution to the Women in AI Datathon 2021 on the theme &quot;combat domestic violence with data and AI&quot;. Our analysis is based on statistics compiled using the DHS&#39; STATcompiler and our own analysis of the sample questionnaire. We note that results based on this sample dataset are consistent with the results for Congo and Benin that we presented at the competition. . We attempted to identify the most relevant questions from the DHS survey questionnaire to identify women in a situation of domestic violence or at risk of domestic violence. We found that the most informative questions were the ones related to emotional violence and control issues. The wealth index is the most informative demographics information, although it scores 6 times less than emotional violence on the mutual information score. . Since domestic is a sensitive and emotional topic for the women experiencing it, we believe that human contact with helpers is of primary importance. Therefore we designed our AI system not with the goal of automating a task, but to provide a tool to inform and assist helpers. This tool comes in the form of a personalized questionnaire generated using a classification tree algorithm. This questionnaire can be used by health or social professionals to efficiently carry out quick interview and form a rapid opinion on whether the interviewed woman is at risk of domestic violence and should be provided with further help. Although we found that the most informative questions are related to emotional violence and control issues, those may be very sensitive issues. For the purpose of short interviews the model could be improved by training in on less intrusive questions, even if those questions are less informative. .",
            "url": "https://abauville.github.io/data_science_blog/2021/04/21/wai-datathon.html",
            "relUrl": "/2021/04/21/wai-datathon.html",
            "date": " • Apr 21, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "import plotly.express as px import numpy as np from IPython.display import HTML . x = np.linspace(-1,1,20) y = x**2 fig = px.scatter(x=x,y=y) HTML(fig.to_html()) . . .",
            "url": "https://abauville.github.io/data_science_blog/2021/04/20/plotly-test.html",
            "relUrl": "/2021/04/20/plotly-test.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://abauville.github.io/data_science_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://abauville.github.io/data_science_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://abauville.github.io/data_science_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://abauville.github.io/data_science_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}